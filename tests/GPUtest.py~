from theano import function, config, shared, tensor, sandbox
import numpy
import time

print(---gpustyle:)

vlen = 10 * 30 * 768  # 10 x #cores x # threads per core
iters = 1000

rng = numpy.random.RandomState(22)
x = shared(numpy.asarray(rng.rand(vlen), config.floatX))
f = function([], tensor.exp(x))
print(f.maker.fgraph.toposort())
t0 = time.time()
for i in range(iters):
    r = f()
t1 = time.time()
print("Looping %d times took %f seconds" % (iters, t1 - t0))
print("Result is %s" % (r,))
if numpy.any([isinstance(x.op, tensor.Elemwise) and
              ('Gpu' not in type(x.op).__name__)
              for x in f.maker.fgraph.toposort()]):
    print('Used the cpu')
else:
    print('Used the gpu')

print("---cpustyle:")

vlenc = 10 * 30 * 768  # 10 x #cores x # threads per core
itersc = 1000

rngc = numpy.random.RandomState(22)
xc = numpy.asarray(rng.rand(vlen), config.floatX)
fc = function([], tensor.exp(xc))
print(fc.maker.fgraph.toposort())
t0c = time.time()
for i in range(itersc):
    rc = fc()
t1c = time.time()
print("Looping %d times took %f seconds" % (iters, t1c - t0c))
print("Result is %s" % (rc,))
if numpy.any([isinstance(xc.op, tensor.Elemwise) and
              ('Gpu' not in type(xc.op).__name__)
              for xc in fc.maker.fgraph.toposort()]):
    print('Used the cpu')
else:
    print('Used the gpu')
