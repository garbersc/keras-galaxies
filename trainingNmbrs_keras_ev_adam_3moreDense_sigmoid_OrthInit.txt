#The training is running for 100 epochs, each with 55421 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#after keyboard interuption:
#eval losses and metrics:
{"loss": [0.042447446805084797, 0.031489624467732673], "sliced_accuracy_std": [0.29643762608288521, 0.25024717900492416], "categorical_accuracy": [0.055871365937064446, 0.59200909534347934], "sliced_accuracy_mean": [0.32691542550846414, 0.54199950392416241], "rmse": [0.20602296591192285, 0.17743441577234187]}
#fit losses:
{"loss": [0.23277918092613401, 0.03182260899211619, 0.031451400217291349, 0.03144256217924022, 0.031449799391265895, 0.031449210251571283, 0.031443305796884806, 0.031457028007114127, 0.031439248728620063, 0.031446358690197997, 0.031449057677706373], "val_loss": [0.25090379740232693, 0.031482338560456208, 0.031479758538870875, 0.031467530817103226, 0.031490155867657452, 0.031469299683802042, 0.031490604903392248, 0.031494014313638415, 0.031475775527096385, 0.031487425042908357, 0.031489626798988722]}
#The training is running for 100 epochs, each with 55421 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#after keyboard interuption:
#eval losses and metrics:
{"loss": [0.043053718364546585], "sliced_accuracy_std": [0.28810146110232471], "categorical_accuracy": [0.59200909534347934], "sliced_accuracy_mean": [0.40173048853622506], "rmse": [0.20748930494758591]}
#fit losses:
{"loss": [0.19668808189573292], "val_loss": [0.20761152133841745]}
#The training is running for 100 epochs, each with 55421 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#after keyboard interuption:
#eval losses and metrics:
{"loss": [0.041393979580367134], "sliced_accuracy_std": [0.30253411349062215], "categorical_accuracy": [0.59200909534347934], "sliced_accuracy_mean": [0.4269493832901079], "rmse": [0.203430907530639]}
#fit losses:
{"loss": [0.20648860454408755], "val_loss": [0.20812130572396245]}
#The training is running for 100 epochs, each with 55421 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#eval losses and metrics:
{"loss": [0.043188327547983824, 0.031071920325413567, 0.031068404786444841, 0.03105721547618806, 0.03105731643899726, 0.031048263865889852, 0.031049124092112912, 0.031049691922678292, 0.031050758646274417, 0.031048859349641491, 0.031049374736626466], "sliced_accuracy_std": [0.21547182132056614, 0.25189119487860501, 0.25571201841649593, 0.25571201841649593, 0.25571201841649593, 0.25571201841649593, 0.25189119487860501, 0.25571201841649593, 0.25571201841649593, 0.25571201841649593, 0.25571201841649593], "categorical_accuracy": [0.055871365937064446, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934], "sliced_accuracy_mean": [0.2696708936534068, 0.54199951755471942, 0.53448404816812911, 0.53448404816812911, 0.53448404816812911, 0.53448404816812911, 0.54199951755471942, 0.53448404816812911, 0.53448404816812911, 0.53448404816812911, 0.53448404816812911], "rmse": [0.20779363278088409, 0.17621564646568394, 0.17620790594048522, 0.17617448787081644, 0.17617458231905672, 0.17615058283604873, 0.17615271452738709, 0.17615540050465081, 0.17615815880470159, 0.1761525520013876, 0.17615353884694249]}
#fit losses:
{"loss": [0.26754703022907977, 0.031176444477130465, 0.031105000629161512, 0.031077176144464931, 0.031086453104875362, 0.031078730340336487, 0.031070426184291417, 0.031070168617548105, 0.031074377369106111, 0.031063509223550244, 0.031066351072893229, 0.031055627535563544, 0.031055294235747512, 0.031056492569534386, 0.031056907291521708, 0.03105733062427278, 0.031057680311003671, 0.031054672397910679, 0.031056401223730441, 0.031055928259674979, 0.031057091358444051, 0.031039559831853032, 0.03104396592686846, 0.031040890449373536, 0.031043461393496712, 0.031038315766919764, 0.031039047797251904, 0.031038012367060306, 0.031038390779146351, 0.031046680582730985, 0.031038970480791336, 0.03103369576226157, 0.031036874155866718, 0.03103518684154807, 0.031037657591521432, 0.031043873765340142, 0.031040469676284949, 0.031040649986156476, 0.031036165380350568, 0.031035109513458781, 0.031032017998683565, 0.031031880038051428, 0.03103127948033298, 0.031033076347466576, 0.031025854047961949, 0.031031025925396805, 0.031030253122088021, 0.031033110580935771, 0.031033680418872972, 0.031030549334391019, 0.031031087801036247, 0.031028213443139482, 0.031032366353892549, 0.031031769078094292, 0.031026937692132217, 0.031029357253258668, 0.031028798763136071, 0.031029937046084904, 0.031026893802289249, 0.031029568087743896, 0.031030373118265408, 0.031029657471285575, 0.031030442898509612, 0.031031095936064408, 0.031028393483903637, 0.031030181522923993, 0.031029823885880079, 0.031026989084044793, 0.031028259463188958, 0.031030108711953368, 0.031028634462414096, 0.031030217587412253, 0.031032338749532443, 0.031031241102805179, 0.031029680447684494, 0.031031489432884078, 0.031031336289043903, 0.031029796856906287, 0.031029074925343368, 0.031032071574543459, 0.031028719842147581, 0.031030132586922877, 0.031027657760545849, 0.031029096038559394, 0.031030881162871646, 0.031029472354249597, 0.031029934448108146, 0.031029510515873097, 0.03102748332973105, 0.031027890827191998, 0.031028786119223457, 0.031026873690420176, 0.031026084164240828, 0.031026542404657905, 0.031026914957214061, 0.03102854807192313, 0.03103153700019172, 0.031028659129581668, 0.031027771530922319, 0.031028275498620757, 0.031029139166687675], "val_loss": [0.27280114090382634, 0.031061928988226691, 0.031090547449721017, 0.031079250952207423, 0.031070135242175761, 0.031067052699379843, 0.031078403700970203, 0.031075533070136087, 0.031072719575041916, 0.031068457229722721, 0.031071922269437884, 0.031067307734435713, 0.031084750513205073, 0.031057266200822591, 0.031057985071731173, 0.031058581156599575, 0.031073459710720706, 0.031062205787823729, 0.031052877080673828, 0.031058971311631423, 0.031068406877496207, 0.031055057082801395, 0.031058722031202159, 0.031051777318345082, 0.031051145484121915, 0.031084182694438158, 0.031048656162797235, 0.031058422401571632, 0.031057167568361875, 0.031057580173153545, 0.031057217884890461, 0.031105438864473613, 0.031051287663513932, 0.031059289673294594, 0.031051169956562503, 0.03105613848580804, 0.031057006987294283, 0.031054538118158219, 0.031053213883038271, 0.031084214872487744, 0.03105731810802654, 0.031049845536902428, 0.031049388162676769, 0.031052351643815236, 0.031050368756859337, 0.03104881349989147, 0.031050706617455504, 0.031052162739771499, 0.031051941291018122, 0.03104958133867311, 0.031048266162355554, 0.031050294496400975, 0.031049204093584269, 0.031049334135681599, 0.031052909118049386, 0.031048965089922217, 0.03105072997388213, 0.031049671115023044, 0.031049097056984803, 0.031048959668980455, 0.031049125606249499, 0.031050001274245561, 0.031049009261567211, 0.031049202610910258, 0.031050573060927657, 0.031049940740547146, 0.031049540239772435, 0.031049162487046991, 0.031048420355914669, 0.03104886134872532, 0.031049694257867168, 0.03105027016735714, 0.031050564826807844, 0.031050332577919369, 0.031050137294837847, 0.031053098629260385, 0.03104997481966253, 0.031049281592570536, 0.031048520745741909, 0.03104896794696636, 0.031050760629021911, 0.031049207094025161, 0.031049870795907479, 0.031049571287286869, 0.03104899402914137, 0.031048701901520655, 0.031048791503313786, 0.031048706470552603, 0.031048887951242977, 0.031048882333962625, 0.031048861955892581, 0.03104910597450812, 0.031048622345970844, 0.031048726679208761, 0.031048819287795806, 0.031049112218317319, 0.031049449101455882, 0.031049492081153193, 0.031048934535523195, 0.031049331304957111, 0.031049377838413165]}
