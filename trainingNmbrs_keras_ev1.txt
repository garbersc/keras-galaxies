#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 100 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#The training is running for 100 epochs, each with 55421 images. The validation sample contains 6157 images. 
#round  ,time, mean_train_loss , mean_valid_loss, mean_sliced_accuracy, mean_train_loss_test, mean_accuracy 
#eval losses and metrics:
{"loss": [0.043430790864203449, 0.029852459730545053, 0.02985263465249792, 0.029850069739000739, 0.029849440240268973, 0.029841076823177423, 0.029839269831396648, 0.029839742420501709, 0.029839563834973604, 0.029838878819312062, 0.029838510363476026], "sliced_accuracy_std": [0.32021679679004134, 0.22618162518965262, 0.22677426741788076, 0.23254461610435337, 0.22668261631454414, 0.23257200113263671, 0.23255815620408424, 0.23255815620408424, 0.23255815620408424, 0.23255815620408424, 0.23255815620408424], "categorical_accuracy": [0.055871365937064446, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934, 0.59200909534347934], "sliced_accuracy_mean": [0.36830216484041167, 0.60783736381860687, 0.60701051332626477, 0.60032190669758168, 0.6072024623836928, 0.60029237547613146, 0.60030714108685657, 0.60030714108685657, 0.60030714108685657, 0.60030714108685657, 0.60030714108685657], "rmse": [0.20839563675499473, 0.17276361915988545, 0.17276434330501125, 0.1727566609129767, 0.1727547190861983, 0.17273051371691733, 0.17272524447802776, 0.17272654094681716, 0.17272619556999252, 0.1727240882452111, 0.17272301215726252]}
#fit losses:
{"loss": [0.042386405229116769, 0.030123014083632823, 0.029914492178713087, 0.02989730899170286, 0.029879223148186869, 0.029872359016244434, 0.029867508386802983, 0.029865952515589312, 0.029860965421721796, 0.029861054137553203, 0.02985943777186251, 0.029857423397442882, 0.029857547959303957, 0.029857222549338334, 0.029848083375062045, 0.029855605405162057, 0.029846357601680126, 0.029848514125927407, 0.029845850003468809, 0.029846937623350139, 0.029845843528557882, 0.029842829649327208, 0.029840565410678033, 0.029837106148225694, 0.029840353321904409, 0.029838362022694204, 0.029832039309511935, 0.029833596994099938, 0.029834004869124551, 0.02983357371642982, 0.029836893873661448, 0.029830095352731456, 0.029831152591778445, 0.029835022107294766, 0.029837678984658274, 0.029836737153620559, 0.029833727671221888, 0.029830977778963593, 0.029831417097640384, 0.029834735783200519, 0.029832970662334663, 0.029829173530685621, 0.029830035017661984, 0.029827639223452069, 0.029828084027624033, 0.029827176557164801, 0.02982813863971704, 0.029827146341081846, 0.029826135694277788, 0.029830464208363321, 0.029825734157005724, 0.029827198713470175, 0.029827631320931063, 0.029824310048653189, 0.029826707161344716, 0.029824711378087114, 0.029825346825322702, 0.029822726916563531, 0.029823716163567496, 0.029824109028134402, 0.029824861615890309, 0.02982773353441125, 0.029825357564847773, 0.02982660586273549, 0.029822339578965323, 0.029822651772119083, 0.029823175344997101, 0.029823878497960518, 0.029827102474025789, 0.029826635096460583, 0.029825385912235956, 0.029823235064450265, 0.029825075716432274, 0.029823425855931292, 0.029824108389227052, 0.029824826256048632, 0.029825267600441508, 0.029822906296776128, 0.029825522865572343, 0.02982376955212436, 0.029823037470807345, 0.029822099447200354, 0.029825324492670831, 0.029824818047517559, 0.029822484810235399, 0.02982409355514945, 0.029823377819878736, 0.029824229471815809, 0.029823640609765265, 0.029824020395451699, 0.029822894245121554, 0.029824270257059745, 0.029821998848465234, 0.0298231775023933, 0.029824342491938265, 0.029821557725622977, 0.029823646261020093, 0.029824908876078783, 0.029823617511500061, 0.029823211344956052, 0.029823102242972414], "val_loss": [0.030446109139742123, 0.029852636867584454, 0.029881245268011742, 0.029864953494430635, 0.029902009000593005, 0.029855709624610902, 0.029870614766123446, 0.029849310291046753, 0.029850227661782976, 0.029867757522011415, 0.029852461895109945, 0.029848248379712505, 0.029847375117393597, 0.02986489264519886, 0.029849455812732684, 0.029847600202192459, 0.029862636283090872, 0.029862191572553039, 0.029844347033598253, 0.029850232833444307, 0.029852636673968588, 0.029843051777328204, 0.029845618735590461, 0.029854491484028207, 0.029841496159750784, 0.029846417503296818, 0.029852073353442816, 0.029844508101730758, 0.029842732096959462, 0.029845797171973845, 0.029850071442820373, 0.029844121876495971, 0.0298477986678348, 0.029841475626788048, 0.029845537648660148, 0.029845128279673661, 0.02984352346006899, 0.02984187707749061, 0.029848911161011876, 0.029841256318700108, 0.029849442571525026, 0.029842837420663546, 0.029841015523486232, 0.029840344029775354, 0.029840476594324407, 0.029841508253784427, 0.02984110454382671, 0.029842556288911477, 0.029840015790072647, 0.029840853771647694, 0.029841078066251796, 0.029839944928480334, 0.029841354534281661, 0.029840775801630325, 0.029840210449650573, 0.029840101081492529, 0.029839946376363991, 0.029840831623202564, 0.029839665821526699, 0.029839017424071128, 0.029839272937116169, 0.02984012270989754, 0.029841063864225397, 0.029839600035695357, 0.029840949533753179, 0.029841461507048393, 0.02983977688745388, 0.029840484241848646, 0.029841072506451155, 0.029839673126895398, 0.029839743667508908, 0.029840587086059529, 0.029839915479506905, 0.029841987864187403, 0.029839970085534528, 0.029840104671856771, 0.029840309161675311, 0.029838685580995613, 0.029839414543223707, 0.029839127446590296, 0.02983956569368593, 0.029839145679457033, 0.02983946927358902, 0.029839088568221598, 0.029839076180738909, 0.02983897761967404, 0.029839151448302306, 0.029838789387537864, 0.029839077064413827, 0.029839101755882367, 0.029838880991742599, 0.029839102270174514, 0.029838915591805674, 0.029838718668132203, 0.029839079821322265, 0.029838744075676923, 0.029838609395571997, 0.029839028785087197, 0.029838635705548174, 0.029838558883914918, 0.029838512226121175]}
